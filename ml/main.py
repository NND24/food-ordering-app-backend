from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from transformers import (
    AutoImageProcessor, 
    AutoModelForImageClassification,
    BlipProcessor,
    BlipForConditionalGeneration,
    AutoTokenizer,
    AutoModelForSeq2SeqLM,
)
from PIL import Image
import requests
import torch
from pydantic import BaseModel
from typing import List, Optional
import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import numpy as np
import logging
import io
import random

logger = logging.getLogger("uvicorn")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def clean_invalid_values(obj):
    if isinstance(obj, dict):
        return {k: clean_invalid_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_invalid_values(v) for v in obj]
    elif isinstance(obj, (float, np.floating)):
        if np.isnan(obj) or np.isinf(obj):
            return 0.0
        return float(obj)
    else:
        return obj


# ---------------------- MODELS ----------------------
class AnalysisItem(BaseModel):
    period: str
    revenue: float
    cost: float
    profit: float
    margin: float
    growth: float

class ScenarioParams(BaseModel):
    trendChange: float = 0     # % thay ƒë·ªïi trend, v√≠ d·ª• 10 = +10%
    seasonalChange: float = 0  # % thay ƒë·ªïi seasonal
    costChange: float = 0      # % thay ƒë·ªïi chi ph√≠

class AnalyzeRequest(BaseModel):
    data: List[AnalysisItem]
    scenario: Optional[ScenarioParams] = None
    groupBy: Optional[str] = "day"  

# ---------------------- ROUTE ----------------------

@app.post("/analyze")
def analyze(req: AnalyzeRequest, period_type: str = "hour"):
    df = pd.DataFrame([item.dict() for item in req.data])
    df = df.sort_values("period")

    # ---- 1. Ph√¢n r√£ chu·ªói th·ªùi gian ----
    decomposition = {}
    ts = df["revenue"].astype(float)

    # X√°c ƒë·ªãnh chu k·ª≥ theo lo·∫°i period
    if period_type == "day":
        decomp_period = 24       # d·ªØ li·ªáu theo gi·ªù
    elif period_type == "week":
        decomp_period = 7        # d·ªØ li·ªáu theo ng√†y
    elif period_type == "month":
        if req.groupBy == "day":
            decomp_period = 30  # kho·∫£ng 30 ng√†y trong th√°ng
        elif req.groupBy == "week":
            decomp_period = 4   # 4 tu·∫ßn trong th√°ng
        else:
            decomp_period = 12  # theo th√°ng
    else:  # year
        decomp_period = 12      # 12 th√°ng

    try:
        if len(ts) < decomp_period * 2:
            trend = ts.rolling(window=max(2, len(ts)//2), min_periods=1).mean().fillna(0)
            seasonal = (ts - trend.rolling(window=2, min_periods=1).mean()).fillna(0)
            resid = (ts - trend - seasonal).fillna(0)
            decomposition = {
                "trend": trend.tolist(),
                "seasonal": seasonal.tolist(),
                "resid": resid.tolist(),
                "note": f"‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu ({len(ts)} ƒëi·ªÉm) ƒë·ªÉ ph√¢n r√£ theo chu k·ª≥ {decomp_period}, d√πng rolling mean thay th·∫ø.",
            }
        else:
            result = seasonal_decompose(ts, model="additive", period=decomp_period)
            decomposition = {
                "trend": result.trend.fillna(0).tolist(),
                "seasonal": result.seasonal.fillna(0).tolist(),
                "resid": result.resid.fillna(0).tolist(),
            }
    except Exception as e:
        decomposition = {"error": str(e)}

    # ---- 2. D·ª± ƒëo√°n n√¢ng c·∫•p v·ªõi seasonal ----
    forecast = {}
    try:
        # Ch·ªçn seasonal_type = "add" v√¨ decomposition d√πng additive
        model = ExponentialSmoothing(
            df["revenue"],
            trend="add",
            seasonal="add",
            seasonal_periods=decomp_period
        )
        model_fit = model.fit()
        pred_full = model_fit.fittedvalues 

        predicted_revenue_next = float(model_fit.forecast(1).tolist()[0])
        predicted_profit_next = predicted_revenue_next - float(df["cost"].iloc[-1])

        forecast = {
            "predictedRevenue": predicted_revenue_next,
            "predictedProfit": predicted_profit_next,
            "avgGrowth": df["revenue"].pct_change().mean() * 100,  # n·∫øu c·∫ßn %
            "predictedRevenueSeries": pred_full.tolist(),   # chu·ªói d·ª± ƒëo√°n
            "predictedProfitSeries": (pred_full - df["cost"]).tolist(),
        }
    except Exception as e:
        logger.exception("Forecast error")   # s·∫Ω in stacktrace
        forecast = {"error": str(e)}

    # ---- 3. Nh·∫≠n ƒë·ªãnh t·ª± ƒë·ªông (gi·ªëng c≈©) ----
    trend_mean = df["revenue"].diff().mean()
    trend_direction = "tƒÉng" if trend_mean > 0 else "gi·∫£m" if trend_mean < 0 else "·ªïn ƒë·ªãnh"
    seasonal_amplitude = abs(df["revenue"].max() - df["revenue"].min()) * 0.1
    seasonal_strength = "m·∫°nh" if df["revenue"].std() > seasonal_amplitude else "y·∫øu"

    insight_messages = []
    if trend_mean > 0:
        insight_messages.append("üìà Xu h∆∞·ªõng tƒÉng: doanh thu c√≥ chi·ªÅu h∆∞·ªõng ƒëi l√™n.")
        if trend_mean > 500:
            insight_messages.append("üöÄ M·ª©c tƒÉng m·∫°nh ‚Äî c√≥ th·ªÉ do marketing ho·∫∑c nhu c·∫ßu tƒÉng.")
    elif trend_mean < 0:
        insight_messages.append("üìâ Xu h∆∞·ªõng gi·∫£m: doanh thu c√≥ d·∫•u hi·ªáu ƒëi xu·ªëng.")
        if trend_mean < -500:
            insight_messages.append("‚ö†Ô∏è C·∫ßn xem l·∫°i gi√° b√°n ho·∫∑c chi·∫øn d·ªãch qu·∫£ng b√°.")
    else:
        insight_messages.append("‚û°Ô∏è Xu h∆∞·ªõng ·ªïn ƒë·ªãnh: doanh thu kh√¥ng thay ƒë·ªïi nhi·ªÅu.")

    if seasonal_strength == "m·∫°nh":
        insight_messages.append("üå§ M√πa v·ª• r√µ r·ªát: c√≥ giai ƒëo·∫°n cao ƒëi·ªÉm v√† th·∫•p ƒëi·ªÉm.")
        insight_messages.append("üí° G·ª£i √Ω: t·∫≠n d·ª•ng cao ƒëi·ªÉm ƒë·ªÉ ƒë·∫©y m·∫°nh khuy·∫øn m√£i.")
    else:
        insight_messages.append("üå§ M√πa v·ª• y·∫øu: doanh thu kh√° ƒë·ªÅu, √≠t b·ªã ·∫£nh h∆∞·ªüng th·ªùi ƒëi·ªÉm.")

    if forecast.get("predictedRevenue"):
        insight_messages.append(
            f"üîÆ D·ª± ƒëo√°n k·ª≥ t·ªõi: doanh thu {forecast['predictedRevenue']:,.0f} ‚Ç´, "
            f"l·ª£i nhu·∫≠n {forecast['predictedProfit']:,.0f} ‚Ç´."
        )

    # ---- 4. M√¥ ph·ªèng k·ªãch b·∫£n ng∆∞·ªùi d√πng (gi·ªëng c≈©) ----
    simulated_forecast = None
    scenario_insights = []

    if req.scenario:
        trend_factor = 1 + req.scenario.trendChange / 100
        seasonal_factor = 1 + req.scenario.seasonalChange / 100
        cost_factor = 1 + req.scenario.costChange / 100

        if "trend" in decomposition and "seasonal" in decomposition:
            simulated_trend = [t * trend_factor for t in decomposition["trend"]]
            simulated_seasonal = [s * seasonal_factor for s in decomposition["seasonal"]]
            simulated_series = [(t + s) for t, s in zip(simulated_trend, simulated_seasonal)]

            next_revenue = simulated_series[-1]
            next_cost = df["cost"].iloc[-1] * cost_factor
            next_profit = next_revenue - next_cost

            simulated_forecast = {
                "predictedRevenue": float(next_revenue),
                "predictedProfit": float(next_profit),
            }

            scenario_insights.append("üß© K·ªãch b·∫£n gi·∫£ l·∫≠p:")
            if req.scenario.trendChange != 0:
                direction = "tƒÉng" if req.scenario.trendChange > 0 else "gi·∫£m"
                scenario_insights.append(f"üìà Xu h∆∞·ªõng {direction} {abs(req.scenario.trendChange)}%.")
            if req.scenario.seasonalChange != 0:
                direction = "tƒÉng" if req.scenario.seasonalChange > 0 else "gi·∫£m"
                scenario_insights.append(f"üå§ M√πa v·ª• {direction} {abs(req.scenario.seasonalChange)}%.")
            if req.scenario.costChange != 0:
                direction = "tƒÉng" if req.scenario.costChange > 0 else "gi·∫£m"
                scenario_insights.append(f"üí∏ Chi ph√≠ {direction} {abs(req.scenario.costChange)}%.")
            scenario_insights.append(
                f"üí∞ K·∫øt qu·∫£ m√¥ ph·ªèng: doanh thu ~ {next_revenue:,.0f} ‚Ç´, "
                f"l·ª£i nhu·∫≠n ~ {next_profit:,.0f} ‚Ç´."
            )
        else:
            scenario_insights.append("‚ö†Ô∏è Kh√¥ng th·ªÉ m√¥ ph·ªèng do thi·∫øu d·ªØ li·ªáu decomposition.")

    response_data = {
        "decomposition": decomposition,
        "forecast": forecast,
        "insightMessages": insight_messages,
        "simulatedForecast": simulated_forecast,
        "scenarioInsights": scenario_insights,
    }

    return clean_invalid_values(response_data)

# ====== B∆Ø·ªöC 1: BLIP sinh m√¥ t·∫£ ti·∫øng Anh ======
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
model = BlipForConditionalGeneration.from_pretrained(
    "Salesforce/blip-image-captioning-large"
).to("cuda" if torch.cuda.is_available() else "cpu")

# ====== B∆Ø·ªöC 2: Model d·ªãch & vi·∫øt l·∫°i ti·∫øng Vi·ªát ======
translator_tokenizer = AutoTokenizer.from_pretrained("VietAI/envit5-translation")
translator_model = AutoModelForSeq2SeqLM.from_pretrained("VietAI/envit5-translation").to(
    "cuda" if torch.cuda.is_available() else "cpu"
)

def improve_vietnamese_caption(english_caption: str) -> str:
    prompt = f"Translate to Vietnamese: {english_caption}"
    inputs = translator_tokenizer(prompt, return_tensors="pt").to(translator_model.device)
    output = translator_model.generate(**inputs, max_new_tokens=100)
    vi_caption = translator_tokenizer.decode(output[0], skip_special_tokens=True)
    return vi_caption.strip()


@app.post("/caption")
def caption(url: str):
    # ==== B∆∞·ªõc 1: t·∫°o m√¥ t·∫£ ti·∫øng Anh ====
    image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
    inputs = processor(image, return_tensors="pt").to(model.device)
    out = model.generate(**inputs, max_new_tokens=50)
    english_caption = processor.decode(out[0], skip_special_tokens=True)

    # ==== B∆∞·ªõc 2: d·ªãch & c·∫£i thi·ªán ====
    vietnamese_caption = improve_vietnamese_caption(english_caption)

    return {"caption_en": english_caption, "caption_vi": vietnamese_caption}


# AI sinh m√¥ t·∫£ t·ª´ ·∫£nh
try:
    from food_info import food_info
except ImportError:
    logger.warning("food_info module not found. Using empty dict.")
    food_info = {}
    
MODEL_CLS_NAME = "./finetuned_food_model" 
processor_cls = None
model_cls = None


def normalize_label(label: str):
    return label.lower().replace("-", " ").replace("_", " ").strip()

food_info_norm = {} # s·∫Ω ƒë∆∞·ª£c ƒëi·ªÅn khi startup

# H√†m classify (T·ª´ code m·ªõi c·ªßa b·∫°n)
def classify_food_topk(image_pil: Image.Image, top_k: int = 3):
    """Ph√¢n lo·∫°i ·∫£nh."""
    if model_cls is None or processor_cls is None:
        raise HTTPException(status_code=503, detail="D·ªãch v·ª• model ch∆∞a s·∫µn s√†ng.")
        
    inputs = processor_cls(images=image_pil.convert("RGB"), return_tensors="pt")
    
    with torch.no_grad():
        outputs = model_cls(**inputs)
    
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]
    topk_prob, topk_indices = torch.topk(probabilities, top_k)
    
    results = []
    for prob, index in zip(topk_prob.tolist(), topk_indices.tolist()):
        label = model_cls.config.id2label[index]
        results.append({"label": label, "score": round(prob, 4)})
        
    return results

# H√†m sinh m√¥ t·∫£ (T·ª´ code m·ªõi c·ªßa b·∫°n)
def generate_description(label: str):
    label_norm = normalize_label(label)
    info = food_info_norm.get(label_norm) 

    if not info:
        return [f"M√≥n {label} th∆°m ngon, h·∫•p d·∫´n, ch·∫Øc ch·∫Øn l√†m h√†i l√≤ng th·ª±c kh√°ch."]

    # ƒê·∫£m b·∫£o c√°c key t·ªìn t·∫°i
    display_name = info.get("display_name", label) 
    ingredients = info.get("ingredients", [])
    taste = info.get("taste", [])
    style = info.get("style", [])

    # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p thi·∫øu d·ªØ li·ªáu trong info
    if len(ingredients) < 2 or len(taste) < 3 or len(style) < 3:
         return [f"M√≥n {display_name} c√≥ th√¥ng tin phong ph√∫ v·ªÅ nguy√™n li·ªáu v√† h∆∞∆°ng v·ªã, l√† m·ªôt l·ª±a ch·ªçn tuy·ªát v·ªùi."]

    # L·∫•y ng·∫´u nhi√™n 2 gi√° tr·ªã t·ª´ taste/style (ƒë·∫£m b·∫£o ch√∫ng kh√°c nhau n·∫øu c·∫ßn)
    random_taste_1 = random.choice(taste)
    random_taste_2 = random.choice([t for t in taste if t != random_taste_1]) # ƒê·∫£m b·∫£o kh√°c nhau

    random_style_desc = random.choice(style) # L·∫•y ng·∫´u nhi√™n m·ªôt m√¥ t·∫£ phong c√°ch/s·ª≠ d·ª•ng

    # L·∫•y 2 th√†nh ph·∫ßn ph·ª• ng·∫´u nhi√™n
    other_ingredients = random.sample(ingredients[1:], 2)
    
    templates = [
        # Template 1: T·∫≠p trung v√†o m·ªôt y·∫øu t·ªë ng·∫´u nhi√™n
        f"{display_name} l√† {random_style_desc}. {ingredients[0]} l√† linh h·ªìn t·∫°o n√™n h∆∞∆°ng v·ªã {random_taste_1} ƒë·∫∑c tr∆∞ng. S·ª± k·∫øt h·ª£p ƒë∆∞·ª£c l√†m gi√†u b·ªüi {', '.join(other_ingredients)} mang l·∫°i tr·∫£i nghi·ªám ·∫©m th·ª±c/th·ª©c u·ªëng kh√≥ qu√™n.",
        
        # Template 2: Tr·∫£i nghi·ªám v√† s·ª± k·∫øt h·ª£p ng·∫´u nhi√™n
        f"Th∆∞·ªüng th·ª©c {display_name} l√† m·ªôt tr·∫£i nghi·ªám v·ªã gi√°c phong ph√∫. ƒêi·ªÉm ƒë·∫∑c s·∫Øc l√† {ingredients[0]} h√≤a quy·ªán c√πng {', '.join(other_ingredients)}, t·∫°o ra m·ªôt s·ª± c√¢n b·∫±ng tuy·ªát v·ªùi gi·ªØa c·∫£m gi√°c {random_taste_1} v√† h∆∞∆°ng v·ªã {random_taste_2}.",
        
        # Template 3: M√¥ t·∫£ T·ªïng quan v√† ƒê√°nh gi√° (S·ª≠ d·ª•ng t·∫•t c·∫£ c√°c th√†nh ph·∫ßn ph·ª• c√≤n l·∫°i)
        f"S·ª©c h·∫•p d·∫´n c·ªßa {display_name} ƒë·∫øn t·ª´ s·ª± ph·ª©c h·ª£p c·ªßa c√°c th√†nh ph·∫ßn. Ngo√†i {ingredients[0]} l√† y·∫øu t·ªë c·ªët l√µi, ƒë√¢y c√≤n l√† s·ª± k·∫øt h·ª£p nhu·∫ßn nhuy·ªÖn gi·ªØa {', '.join(ingredients[1:])}. T·ªïng th·ªÉ mang l·∫°i c·∫£m gi√°c {random_taste_1} v√† l√† ƒë·∫°i di·ªán cho {random_style_desc}."
    ]
    
    return templates

@app.on_event("startup")
async def load_resources():
    global processor_cls, model_cls, food_info_norm, food_info
    try:
        
        # 1. Load Model Ph√¢n lo·∫°i (S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n c·ª•c b·ªô c·ªßa b·∫°n)
        print("\nƒêang t·∫£i model Ph√¢n lo·∫°i ·∫¢nh Finetuned Food Model...")
        processor_cls = AutoImageProcessor.from_pretrained(MODEL_CLS_NAME)
        model_cls = AutoModelForImageClassification.from_pretrained(MODEL_CLS_NAME)
        model_cls.eval() 
        
        # 2. Chu·∫©n h√≥a food_info
        food_info_norm = {normalize_label(k): v for k, v in food_info.items()}
        
        print("‚úÖ T·∫£i model v√† d·ªØ li·ªáu th√†nh c√¥ng.")
        
    except Exception as e:
        print(f"\n‚ùå L·ªñI KH√îNG TH·ªÇ T·∫¢I MODEL T·ª™ {MODEL_CLS_NAME}: {e}")
        logger.error(f"L·ªói t·∫£i model: {e}")
        model_cls = None

# ----------------------------------------------------------------------
# Endpoint API Ch√≠nh: Sinh M√¥ T·∫£ t·ª´ ·∫¢nh
# ----------------------------------------------------------------------

@app.post("/generate-caption-from-image", 
          response_model=dict, 
          summary="Ph√¢n lo·∫°i ·∫£nh v√† sinh ra 3 m√¥ t·∫£ m√≥n ƒÉn")
async def generate_caption(top_k: int = 1, file: UploadFile = File(..., description="File ·∫£nh m√≥n ƒÉn")):
    
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File t·∫£i l√™n ph·∫£i l√† ·∫£nh.")
    
    try:
        # ƒê·ªçc ·∫£nh v√† chuy·ªÉn sang ƒë·ªëi t∆∞·ª£ng PIL
        image_bytes = await file.read()
        image_pil = Image.open(io.BytesIO(image_bytes))
        
        # 1. Ph√¢n lo·∫°i ·∫£nh
        predictions = classify_food_topk(image_pil, top_k=top_k)
        
        if not predictions:
             raise HTTPException(status_code=500, detail="Kh√¥ng th·ªÉ d·ª± ƒëo√°n m√≥n ƒÉn t·ª´ ·∫£nh.")
        
        # 2. L·∫•y nh√£n d·ª± ƒëo√°n cao nh·∫•t
        best_label = predictions[0]['label']
        
        # 3. Sinh 3 m√¥ t·∫£
        descriptions = generate_description(best_label)
        
        # 4. Tr·∫£ v·ªÅ k·∫øt qu·∫£
        return {
            "success": True, 
            "best_prediction": predictions[0],
            "top_predictions": predictions,
            "descriptions": descriptions # Tr·∫£ v·ªÅ list 3 m√¥ t·∫£
        }
    except HTTPException as h:
        raise h 
    except Exception as e:
        logger.error(f"L·ªói x·ª≠ l√Ω request: {e}")
        raise HTTPException(status_code=500, detail="L·ªói server khi ph√¢n lo·∫°i v√† sinh m√¥ t·∫£.")