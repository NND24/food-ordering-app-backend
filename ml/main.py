from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from transformers import (
    BlipProcessor,
    BlipForConditionalGeneration,
    AutoTokenizer,
    AutoModelForSeq2SeqLM,
)
from PIL import Image
import requests
import torch
from pydantic import BaseModel
from typing import List, Optional
import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import numpy as np
import logging

logger = logging.getLogger("uvicorn")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def clean_invalid_values(obj):
    if isinstance(obj, dict):
        return {k: clean_invalid_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_invalid_values(v) for v in obj]
    elif isinstance(obj, (float, np.floating)):
        if np.isnan(obj) or np.isinf(obj):
            return 0.0
        return float(obj)
    else:
        return obj


# ---------------------- MODELS ----------------------
class AnalysisItem(BaseModel):
    period: str
    revenue: float
    cost: float
    profit: float
    margin: float
    growth: float

class ScenarioParams(BaseModel):
    trendChange: float = 0     # % thay ƒë·ªïi trend, v√≠ d·ª• 10 = +10%
    seasonalChange: float = 0  # % thay ƒë·ªïi seasonal
    costChange: float = 0      # % thay ƒë·ªïi chi ph√≠

class AnalyzeRequest(BaseModel):
    data: List[AnalysisItem]
    scenario: Optional[ScenarioParams] = None
    groupBy: Optional[str] = "day"  

# ---------------------- ROUTE ----------------------

@app.post("/analyze")
def analyze(req: AnalyzeRequest, period_type: str = "hour"):
    df = pd.DataFrame([item.dict() for item in req.data])
    df = df.sort_values("period")

    # ---- 1. Ph√¢n r√£ chu·ªói th·ªùi gian ----
    decomposition = {}
    ts = df["revenue"].astype(float)

    # X√°c ƒë·ªãnh chu k·ª≥ theo lo·∫°i period
    if period_type == "day":
        decomp_period = 24       # d·ªØ li·ªáu theo gi·ªù
    elif period_type == "week":
        decomp_period = 7        # d·ªØ li·ªáu theo ng√†y
    elif period_type == "month":
        if req.groupBy == "day":
            decomp_period = 30  # kho·∫£ng 30 ng√†y trong th√°ng
        elif req.groupBy == "week":
            decomp_period = 4   # 4 tu·∫ßn trong th√°ng
        else:
            decomp_period = 12  # theo th√°ng
    else:  # year
        decomp_period = 12      # 12 th√°ng

    try:
        if len(ts) < decomp_period * 2:
            trend = ts.rolling(window=max(2, len(ts)//2), min_periods=1).mean().fillna(0)
            seasonal = (ts - trend.rolling(window=2, min_periods=1).mean()).fillna(0)
            resid = (ts - trend - seasonal).fillna(0)
            decomposition = {
                "trend": trend.tolist(),
                "seasonal": seasonal.tolist(),
                "resid": resid.tolist(),
                "note": f"‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu ({len(ts)} ƒëi·ªÉm) ƒë·ªÉ ph√¢n r√£ theo chu k·ª≥ {decomp_period}, d√πng rolling mean thay th·∫ø.",
            }
        else:
            result = seasonal_decompose(ts, model="additive", period=decomp_period)
            decomposition = {
                "trend": result.trend.fillna(0).tolist(),
                "seasonal": result.seasonal.fillna(0).tolist(),
                "resid": result.resid.fillna(0).tolist(),
            }
    except Exception as e:
        decomposition = {"error": str(e)}

    # ---- 2. D·ª± ƒëo√°n n√¢ng c·∫•p v·ªõi seasonal ----
    forecast = {}
    try:
        # Ch·ªçn seasonal_type = "add" v√¨ decomposition d√πng additive
        model = ExponentialSmoothing(
            df["revenue"],
            trend="add",
            seasonal="add",
            seasonal_periods=decomp_period
        )
        model_fit = model.fit()
        pred_full = model_fit.fittedvalues 

        predicted_revenue_next = float(model_fit.forecast(1).tolist()[0])
        predicted_profit_next = predicted_revenue_next - float(df["cost"].iloc[-1])

        forecast = {
            "predictedRevenue": predicted_revenue_next,
            "predictedProfit": predicted_profit_next,
            "avgGrowth": df["revenue"].pct_change().mean() * 100,  # n·∫øu c·∫ßn %
            "predictedRevenueSeries": pred_full.tolist(),   # chu·ªói d·ª± ƒëo√°n
            "predictedProfitSeries": (pred_full - df["cost"]).tolist(),
        }
    except Exception as e:
        logger.exception("Forecast error")   # s·∫Ω in stacktrace
        forecast = {"error": str(e)}

    # ---- 3. Nh·∫≠n ƒë·ªãnh t·ª± ƒë·ªông (gi·ªëng c≈©) ----
    trend_mean = df["revenue"].diff().mean()
    trend_direction = "tƒÉng" if trend_mean > 0 else "gi·∫£m" if trend_mean < 0 else "·ªïn ƒë·ªãnh"
    seasonal_amplitude = abs(df["revenue"].max() - df["revenue"].min()) * 0.1
    seasonal_strength = "m·∫°nh" if df["revenue"].std() > seasonal_amplitude else "y·∫øu"

    insight_messages = []
    if trend_mean > 0:
        insight_messages.append("üìà Xu h∆∞·ªõng tƒÉng: doanh thu c√≥ chi·ªÅu h∆∞·ªõng ƒëi l√™n.")
        if trend_mean > 500:
            insight_messages.append("üöÄ M·ª©c tƒÉng m·∫°nh ‚Äî c√≥ th·ªÉ do marketing ho·∫∑c nhu c·∫ßu tƒÉng.")
    elif trend_mean < 0:
        insight_messages.append("üìâ Xu h∆∞·ªõng gi·∫£m: doanh thu c√≥ d·∫•u hi·ªáu ƒëi xu·ªëng.")
        if trend_mean < -500:
            insight_messages.append("‚ö†Ô∏è C·∫ßn xem l·∫°i gi√° b√°n ho·∫∑c chi·∫øn d·ªãch qu·∫£ng b√°.")
    else:
        insight_messages.append("‚û°Ô∏è Xu h∆∞·ªõng ·ªïn ƒë·ªãnh: doanh thu kh√¥ng thay ƒë·ªïi nhi·ªÅu.")

    if seasonal_strength == "m·∫°nh":
        insight_messages.append("üå§ M√πa v·ª• r√µ r·ªát: c√≥ giai ƒëo·∫°n cao ƒëi·ªÉm v√† th·∫•p ƒëi·ªÉm.")
        insight_messages.append("üí° G·ª£i √Ω: t·∫≠n d·ª•ng cao ƒëi·ªÉm ƒë·ªÉ ƒë·∫©y m·∫°nh khuy·∫øn m√£i.")
    else:
        insight_messages.append("üå§ M√πa v·ª• y·∫øu: doanh thu kh√° ƒë·ªÅu, √≠t b·ªã ·∫£nh h∆∞·ªüng th·ªùi ƒëi·ªÉm.")

    if forecast.get("predictedRevenue"):
        insight_messages.append(
            f"üîÆ D·ª± ƒëo√°n k·ª≥ t·ªõi: doanh thu {forecast['predictedRevenue']:,.0f} ‚Ç´, "
            f"l·ª£i nhu·∫≠n {forecast['predictedProfit']:,.0f} ‚Ç´."
        )

    # ---- 4. M√¥ ph·ªèng k·ªãch b·∫£n ng∆∞·ªùi d√πng (gi·ªëng c≈©) ----
    simulated_forecast = None
    scenario_insights = []

    if req.scenario:
        trend_factor = 1 + req.scenario.trendChange / 100
        seasonal_factor = 1 + req.scenario.seasonalChange / 100
        cost_factor = 1 + req.scenario.costChange / 100

        if "trend" in decomposition and "seasonal" in decomposition:
            simulated_trend = [t * trend_factor for t in decomposition["trend"]]
            simulated_seasonal = [s * seasonal_factor for s in decomposition["seasonal"]]
            simulated_series = [(t + s) for t, s in zip(simulated_trend, simulated_seasonal)]

            next_revenue = simulated_series[-1]
            next_cost = df["cost"].iloc[-1] * cost_factor
            next_profit = next_revenue - next_cost

            simulated_forecast = {
                "predictedRevenue": float(next_revenue),
                "predictedProfit": float(next_profit),
            }

            scenario_insights.append("üß© K·ªãch b·∫£n gi·∫£ l·∫≠p:")
            if req.scenario.trendChange != 0:
                direction = "tƒÉng" if req.scenario.trendChange > 0 else "gi·∫£m"
                scenario_insights.append(f"üìà Xu h∆∞·ªõng {direction} {abs(req.scenario.trendChange)}%.")
            if req.scenario.seasonalChange != 0:
                direction = "tƒÉng" if req.scenario.seasonalChange > 0 else "gi·∫£m"
                scenario_insights.append(f"üå§ M√πa v·ª• {direction} {abs(req.scenario.seasonalChange)}%.")
            if req.scenario.costChange != 0:
                direction = "tƒÉng" if req.scenario.costChange > 0 else "gi·∫£m"
                scenario_insights.append(f"üí∏ Chi ph√≠ {direction} {abs(req.scenario.costChange)}%.")
            scenario_insights.append(
                f"üí∞ K·∫øt qu·∫£ m√¥ ph·ªèng: doanh thu ~ {next_revenue:,.0f} ‚Ç´, "
                f"l·ª£i nhu·∫≠n ~ {next_profit:,.0f} ‚Ç´."
            )
        else:
            scenario_insights.append("‚ö†Ô∏è Kh√¥ng th·ªÉ m√¥ ph·ªèng do thi·∫øu d·ªØ li·ªáu decomposition.")

    response_data = {
        "decomposition": decomposition,
        "forecast": forecast,
        "insightMessages": insight_messages,
        "simulatedForecast": simulated_forecast,
        "scenarioInsights": scenario_insights,
    }

    return clean_invalid_values(response_data)

# ====== B∆Ø·ªöC 1: BLIP sinh m√¥ t·∫£ ti·∫øng Anh ======
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
model = BlipForConditionalGeneration.from_pretrained(
    "Salesforce/blip-image-captioning-large"
).to("cuda" if torch.cuda.is_available() else "cpu")

# ====== B∆Ø·ªöC 2: Model d·ªãch & vi·∫øt l·∫°i ti·∫øng Vi·ªát ======
translator_tokenizer = AutoTokenizer.from_pretrained("VietAI/envit5-translation")
translator_model = AutoModelForSeq2SeqLM.from_pretrained("VietAI/envit5-translation").to(
    "cuda" if torch.cuda.is_available() else "cpu"
)

def improve_vietnamese_caption(english_caption: str) -> str:
    prompt = f"Translate to Vietnamese: {english_caption}"
    inputs = translator_tokenizer(prompt, return_tensors="pt").to(translator_model.device)
    output = translator_model.generate(**inputs, max_new_tokens=100)
    vi_caption = translator_tokenizer.decode(output[0], skip_special_tokens=True)
    return vi_caption.strip()


@app.post("/caption")
def caption(url: str):
    # ==== B∆∞·ªõc 1: t·∫°o m√¥ t·∫£ ti·∫øng Anh ====
    image = Image.open(requests.get(url, stream=True).raw).convert("RGB")
    inputs = processor(image, return_tensors="pt").to(model.device)
    out = model.generate(**inputs, max_new_tokens=50)
    english_caption = processor.decode(out[0], skip_special_tokens=True)

    # ==== B∆∞·ªõc 2: d·ªãch & c·∫£i thi·ªán ====
    vietnamese_caption = improve_vietnamese_caption(english_caption)

    return {"caption_en": english_caption, "caption_vi": vietnamese_caption}
