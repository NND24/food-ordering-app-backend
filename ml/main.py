from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from transformers import (
    AutoImageProcessor, 
    AutoModelForImageClassification,
)
from PIL import Image
import requests
import torch
from pydantic import BaseModel
from typing import List, Optional
import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import numpy as np
import logging
import io
import random
import httpx

logger = logging.getLogger("uvicorn")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def clean_invalid_values(obj):
    if isinstance(obj, dict):
        return {k: clean_invalid_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_invalid_values(v) for v in obj]
    elif isinstance(obj, (float, np.floating)):
        if np.isnan(obj) or np.isinf(obj):
            return 0.0
        return float(obj)
    else:
        return obj


# ---------------------- MODELS ----------------------
class AnalysisItem(BaseModel):
    period: str
    revenue: float
    cost: float
    profit: float
    margin: float
    growth: float

class ScenarioParams(BaseModel):
    trendChange: float = 0     # % thay ƒë·ªïi trend, v√≠ d·ª• 10 = +10%
    seasonalChange: float = 0  # % thay ƒë·ªïi seasonal
    costChange: float = 0      # % thay ƒë·ªïi chi ph√≠

class AnalyzeRequest(BaseModel):
    data: List[AnalysisItem]
    scenario: Optional[ScenarioParams] = None
    groupBy: Optional[str] = "day"  

# ---------------------- ROUTE ----------------------
@app.post("/analyze")
def analyze(req: AnalyzeRequest, period_type: str = "hour"):
    df = pd.DataFrame([item.dict() for item in req.data])

    # -----------------------------
    # 0. Chu·∫©n ho√° th·ªùi gian
    # -----------------------------
    df["period"] = pd.to_datetime(df["period"], errors="coerce")
    df = df.sort_values("period")

    # -----------------------------
    # ‚≠ê 1. AUTO RESAMPLE (TƒÇNG DATAPOINT)
    # -----------------------------
    df = df.set_index("period")

    def auto_boost_datapoint(df):
        """
        TƒÉng s·ªë l∆∞·ª£ng datapoint b·∫±ng resample & interpolate tuy·∫øn t√≠nh.
        Th·ª≠ l·∫ßn l∆∞·ª£t 6H ‚Üí 3H ‚Üí 1H.
        """
        if len(df) >= 40:
            return df  # ƒë√£ ƒë·ªß nhi·ªÅu ‚Üí kh√¥ng c·∫ßn tƒÉng

        for freq in ["6h", "3h", "1h"]:
            boosted = df.resample(freq).interpolate(method="linear")
            if len(boosted) >= 40:   # ƒë·ªß datapoint ƒë·ªÉ decomposition
                return boosted

        return boosted  # d√πng b·∫£n cu·ªëi c√πng (1H)

    df = auto_boost_datapoint(df)
    ts = df["revenue"]

    # -----------------------------
    # ‚≠ê 2. T√çNH DECOMP_PERIOD
    # -----------------------------
    if period_type == "day":
        base_period = 24
    elif period_type == "week":
        base_period = 7
    elif period_type == "month":
        base_period = 30
    else:
        base_period = 12

    # N·∫øu boost datapoint l√™n ‚Üí chu k·ª≥ c·∫ßn scale l·∫°i
    # V√≠ d·ª•: ng√†y ‚Üí resample 6 gi·ªù ‚áí 1 ng√†y th√†nh 4 ƒëi·ªÉm
    inferred_points_per_day = int(24 / (df.index[1] - df.index[0]).total_seconds() * 3600)
    decomp_period = max(2, base_period * inferred_points_per_day // 24)

    # Gi·ªõi h·∫°n theo ƒë·ªô d√†i chu·ªói
    if len(ts) < decomp_period * 2:
        decomp_period = max(2, len(ts) // 3)

    # -----------------------------
    # ‚≠ê 3. PH√ÇN R√É CHU·ªñI (DECOMPOSE)
    # -----------------------------
    try:
        if len(ts) < 10:
            raise Exception("Not enough data for decomposition")

        result = seasonal_decompose(ts, model="additive", period=decomp_period)
        decomposition = {
            "trend": result.trend.fillna(0).tolist(),
            "seasonal": result.seasonal.fillna(0).tolist(),
            "resid": result.resid.fillna(0).tolist(),
            "periodUsed": decomp_period,
        }
    except Exception as e:
        # fallback: rolling
        trend = ts.rolling(window=max(2, len(ts)//2)).mean().fillna(0)
        seasonal = ts - trend.rolling(window=2, min_periods=1).mean().fillna(0)
        decomposition = {
            "trend": trend.tolist(),
            "seasonal": seasonal.tolist(),
            "resid": (ts - trend - seasonal).fillna(0).tolist(),
            "periodUsed": decomp_period,
            "note": f"Not enough data for full decomposition, using rolling instead: {str(e)}"
        }

    # -----------------------------
    # ‚≠ê 4. D·ª∞ B√ÅO (ExponentialSmoothing)
    # -----------------------------
    try:
        model = ExponentialSmoothing(
            df["revenue"],
            trend="add",
            seasonal="add",
            seasonal_periods=decomp_period
        )
        model_fit = model.fit()

        predicted_revenue_next = float(model_fit.forecast(1)[0])
        predicted_profit_next = predicted_revenue_next - float(df["cost"].iloc[-1])

        pred_full = model_fit.fittedvalues
        forecast = {
            "predictedRevenue": predicted_revenue_next,
            "predictedProfit": predicted_profit_next,
            "avgGrowth": df["revenue"].pct_change().mean() * 100,
            "predictedRevenueSeries": pred_full.tolist(),
            "predictedProfitSeries": (pred_full - df["cost"]).tolist(),
        }

    except Exception as e:
        forecast = {"error": str(e)}

    # -----------------------------
    # ‚≠ê 5. INSIGHTS 
    # -----------------------------
    trend_mean = df["revenue"].diff().mean()
    trend_direction = "tƒÉng" if trend_mean > 0 else "gi·∫£m" if trend_mean < 0 else "·ªïn ƒë·ªãnh"
    seasonal_strength = (
        "m·∫°nh" if df["revenue"].std() > abs(df["revenue"].max() - df["revenue"].min()) * 0.1 else "y·∫øu"
    )

    insight_messages = []
    if trend_mean > 0:
        insight_messages.append("Xu h∆∞·ªõng tƒÉng: doanh thu c√≥ chi·ªÅu h∆∞·ªõng ƒëi l√™n.")
        if trend_mean > 500:
            insight_messages.append("M·ª©c tƒÉng m·∫°nh ‚Äî c√≥ th·ªÉ do marketing ho·∫∑c nhu c·∫ßu tƒÉng.")
    elif trend_mean < 0:
        insight_messages.append("Xu h∆∞·ªõng gi·∫£m: doanh thu c√≥ d·∫•u hi·ªáu ƒëi xu·ªëng.")
        if trend_mean < -500:
            insight_messages.append("C·∫ßn xem l·∫°i gi√° b√°n ho·∫∑c chi·∫øn d·ªãch qu·∫£ng b√°.")
    else:
        insight_messages.append("Xu h∆∞·ªõng ·ªïn ƒë·ªãnh.")

    if seasonal_strength == "m·∫°nh":
        insight_messages.append("M√πa v·ª• r√µ r·ªát: c√≥ giai ƒëo·∫°n cao ƒëi·ªÉm ‚Äì th·∫•p ƒëi·ªÉm.")
    else:
        insight_messages.append("M√πa v·ª• y·∫øu: doanh thu kh√° ƒë·ªÅu.")

    if forecast.get("predictedRevenue"):
        insight_messages.append(
            f"K·ª≥ t·ªõi: doanh thu {forecast['predictedRevenue']:,.0f} ‚Ç´, l·ª£i nhu·∫≠n {forecast['predictedProfit']:,.0f} ‚Ç´."
        )

    # -----------------------------
    # ‚≠ê 6. M√î PH·ªéNG K·ªäCH B·∫¢N (gi·ªØ logic)
    # -----------------------------
    simulated_forecast = None
    scenario_insights = []

    if req.scenario and "trend" in decomposition:
        trend_factor = 1 + req.scenario.trendChange / 100
        seasonal_factor = 1 + req.scenario.seasonalChange / 100
        cost_factor = 1 + req.scenario.costChange / 100

        simulated_series = [
            t * trend_factor + s * seasonal_factor
            for t, s in zip(decomposition["trend"], decomposition["seasonal"])
        ]

        next_revenue = simulated_series[-1]
        next_cost = df["cost"].iloc[-1] * cost_factor
        next_profit = next_revenue - next_cost

        simulated_forecast = {
            "predictedRevenue": float(next_revenue),
            "predictedProfit": float(next_profit),
        }

        scenario_insights.append("üß© K·ªãch b·∫£n gi·∫£ l·∫≠p:")
        if req.scenario.trendChange != 0:
            scenario_insights.append(f"üìà Xu h∆∞·ªõng thay ƒë·ªïi {req.scenario.trendChange}%.")
        if req.scenario.seasonalChange != 0:
            scenario_insights.append(f"üå§ M√πa v·ª• thay ƒë·ªïi {req.scenario.seasonalChange}%.")
        if req.scenario.costChange != 0:
            scenario_insights.append(f"üí∏ Chi ph√≠ thay ƒë·ªïi {req.scenario.costChange}%.")
        scenario_insights.append(
            f"üí∞ D·ª± b√°o: doanh thu {next_revenue:,.0f} ‚Ç´, l·ª£i nhu·∫≠n {next_profit:,.0f} ‚Ç´."
        )

    def round_values(obj, digits=2):
        if isinstance(obj, float):
            return round(obj, digits)
        if isinstance(obj, list):
            return [round_values(x, digits) for x in obj]
        if isinstance(obj, dict):
            return {k: round_values(v, digits) for k, v in obj.items()}
        return obj

    return round_values(
        clean_invalid_values({
            "decomposition": decomposition,
            "forecast": forecast,
            "insightMessages": insight_messages,
            "simulatedForecast": simulated_forecast,
            "scenarioInsights": scenario_insights,
        }),
        digits=2
    )


# AI sinh m√¥ t·∫£ t·ª´ ·∫£nh
try:
    from food_info import food_info
except ImportError:
    logger.warning("food_info module not found. Using empty dict.")
    food_info = {}
    
MODEL_CLS_NAME = "./finetuned_food_model" 
processor_cls = None
model_cls = None


def normalize_label(label: str):
    return label.lower().replace("-", " ").replace("_", " ").strip()

food_info_norm = {}

# H√†m classify (T·ª´ code m·ªõi c·ªßa b·∫°n)
def classify_food(image_pil: Image.Image):
    """Ph√¢n lo·∫°i ·∫£nh v√† ch·ªâ tr·∫£ v·ªÅ k·∫øt qu·∫£ c√≥ ƒë·ªô ch√≠nh x√°c cao nh·∫•t."""
    if model_cls is None or processor_cls is None:
        raise HTTPException(status_code=503, detail="D·ªãch v·ª• model ch∆∞a s·∫µn s√†ng.")
        
    inputs = processor_cls(images=image_pil.convert("RGB"), return_tensors="pt")
    
    with torch.no_grad():
        outputs = model_cls(**inputs)
    
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]
    _, top_index = torch.max(probabilities, dim=-1)
    label = model_cls.config.id2label[top_index.item()]
    
    return label

# H√†m sinh m√¥ t·∫£ (T·ª´ code m·ªõi c·ªßa b·∫°n)
# H√†m sinh m√¥ t·∫£ (ƒê√É S·ª¨A L·ªñI LOGIC V√Ä TH·ª® T·ª∞)
def generate_caption(label: str, user_extras: List[str] = None) -> str:
    # 0. Chu·∫©n b·ªã d·ªØ li·ªáu v√† ki·ªÉm tra Fallback 1
    # L√†m s·∫°ch, chuy·ªÉn ch·ªØ th∆∞·ªùng v√† l·ªçc b·ªè ph·∫ßn t·ª≠ r·ªóng cho user_extras
    user_extras = [item.strip().lower() for item in user_extras if item.strip()] if user_extras else []
    
    label_norm = normalize_label(label)
    info = food_info_norm.get(label_norm)

    if not info:
        return f"M√≥n {label} th∆°m ngon, h·∫•p d·∫´n, ch·∫Øc ch·∫Øn l√†m h√†i l√≤ng th·ª±c kh√°ch."

    # 1. L·∫•y d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng v√† ki·ªÉm tra Fallback 2
    display_name = info.get("display_name", label)
    taste = info.get("taste", [])
    texture = info.get("texture", [])
    style = info.get("style", [])

    all_sensations = taste + texture # Bao g·ªìm c·∫£ V·ªã v√† K·∫øt c·∫•u
    
    # Fallback 2: Ki·ªÉm tra d·ªØ li·ªáu c·ªët l√µi (√çt nh·∫•t 2 m√¥ t·∫£ c·∫£m gi√°c v√† c√≥ phong c√°ch)
    if len(all_sensations) < 2 or not style:
        return f"M√≥n {display_name} c√≥ h∆∞∆°ng v·ªã v√† phong c√°ch ƒë·ªôc ƒë√°o, l√† m·ªôt l·ª±a ch·ªçn tuy·ªát v·ªùi."

    # 2. L·ª±a ch·ªçn Ng·∫´u nhi√™n
    # Ch·ªçn ng·∫´u nhi√™n 2 m√¥ t·∫£ c·∫£m gi√°c kh√°c nhau
    sensation_1, sensation_2 = random.sample(all_sensations, k=2) 
    style_desc = random.choice(style)

    random_user_extras = "c√°c nguy√™n li·ªáu tinh t√∫y"
    if user_extras:
        # L·∫•y 1-3 nguy√™n li·ªáu ng·∫´u nhi√™n ƒë·ªÉ l√†m vƒÉn
        random_user_extras = ", ".join(random.sample(user_extras, k=min(len(user_extras), random.randint(1, 3))))

    # 4. Templates (T·ªëi ∆∞u h√≥a v√† ƒêa d·∫°ng h∆°n)
    templates = [
        # Template A: Nh·∫•n m·∫°nh Phong c√°ch v√† C·∫£m gi√°c
        (f"M√≥n {display_name} th·ªÉ hi·ªán ƒë√∫ng tinh hoa {style_desc}. "
        f"H∆∞∆°ng v·ªã n√†y tr·ªü n√™n ƒë·∫∑c s·∫Øc v·ªõi th√†nh ph·∫ßn c·ªët l√µi l√† {random_user_extras} "
        f"v√† mang l·∫°i c·∫£m gi√°c {sensation_1} kh√≥ qu√™n, h√≤a quy·ªán v·ªõi {sensation_2}."),
        
        # Template B: Nh·∫•n m·∫°nh V·ªã gi√°c, K·∫øt c·∫•u v√† Nguy√™n li·ªáu (Ph√π h·ª£p cho m·ªçi lo·∫°i m√≥n)
        (f"Th∆∞·ªüng th·ª©c {display_name} l√† m·ªôt tr·∫£i nghi·ªám {style_desc} phong ph√∫. "
        f"S·ª± c√¢n b·∫±ng tuy·ªát v·ªùi gi·ªØa v·ªã {sensation_1} v√† k·∫øt c·∫•u {sensation_2} "
        f"ƒë∆∞·ª£c l√†m gi√†u th√™m b·ªüi {random_user_extras}."), # Thay ƒë·ªïi v·ªã tr√≠ ingredient_clause_t1_t2
        
        # Template C: M√¥ t·∫£ ng·∫Øn g·ªçn, thu h√∫t v√† Ng·ªØ c·∫£nh (R·∫•t ph√π h·ª£p cho m√≥n n∆∞·ªõc/tr√°ng mi·ªáng)
        (f"M√≥n {display_name} ƒë·ªôc ƒë√°o v√† h·∫•p d·∫´n t·∫°o n√™n b·ªüi"
        f" s·ª± k·∫øt h·ª£p gi·ªØa c√°c th√†nh ph·∫ßn nh∆∞ {random_user_extras}. V·ªã {sensation_1} v√† c·∫£m gi√°c {sensation_2} "
        f"s·∫Ω chinh ph·ª•c m·ªçi th·ª±c kh√°ch."),
        
        # Template D: Nh·∫•n m·∫°nh s·ª± ph·ª©c h·ª£p, Tinh t·∫ø v√† Th√†nh ph·∫ßn
        (f"S·ª©c h·∫•p d·∫´n c·ªßa {display_name} ƒë·∫øn t·ª´ s·ª± ph·ª©c h·ª£p tinh t·∫ø. "
        f"T·ªïng th·ªÉ mang l·∫°i c·∫£m gi√°c {sensation_1} v√† {sensation_2} kh√≥ t·∫£. "
        f"L√† m·ªôt {style_desc} ƒë∆∞·ª£c t·∫°o n√™n b·ªüi {random_user_extras},..."),
    ]
    
    return random.choice(templates)

@app.on_event("startup")
async def load_resources():
    global processor_cls, model_cls, food_info_norm, food_info
    try:
        # 1. Load Model Ph√¢n lo·∫°i
        print("\nƒêang t·∫£i model Ph√¢n lo·∫°i ·∫¢nh Finetuned Food Model...")
        processor_cls = AutoImageProcessor.from_pretrained(MODEL_CLS_NAME)
        model_cls = AutoModelForImageClassification.from_pretrained(MODEL_CLS_NAME)
        model_cls.eval() 
        
        # 2. Chu·∫©n h√≥a food_info
        food_info_norm = {normalize_label(k): v for k, v in food_info.items()}
        
        print("‚úÖ T·∫£i model v√† d·ªØ li·ªáu th√†nh c√¥ng.")
        
    except Exception as e:
        print(f"\n‚ùå L·ªñI KH√îNG TH·ªÇ T·∫¢I MODEL T·ª™ {MODEL_CLS_NAME}: {e}")
        logger.error(f"L·ªói t·∫£i model: {e}")
        model_cls = None

# ----------------------------------------------------------------------
# Endpoint API Ch√≠nh: Sinh M√¥ T·∫£ t·ª´ ·∫¢nh
# ----------------------------------------------------------------------

@app.post("/generate-caption-from-image", 
          response_model=dict, 
          summary="Ph√¢n lo·∫°i ·∫£nh v√† sinh ra m√¥ t·∫£ m√≥n ƒÉn")
async def generate_caption_unified(
    ingredients: List[str] = Form([], description="C√°c th√†nh ph·∫ßn trong m√≥n ƒÉn."),
    file: Optional[UploadFile] = File(None, description="File ·∫£nh m√≥n ƒÉn (ch·ªâ c·∫ßn 1 trong 2: File ho·∫∑c URL)"),
    image_url: Optional[str] = Form(None, description="URL c·ªßa ·∫£nh m√≥n ƒÉn (ch·ªâ c·∫ßn 1 trong 2: File ho·∫∑c URL)")
):
    
    # --- 1. Ki·ªÉm tra ƒë·∫ßu v√†o v√† T·∫£i/ƒê·ªçc ·∫£nh ---
    
    if not file and not image_url:
        raise HTTPException(status_code=400, detail="Vui l√≤ng cung c·∫•p File ·∫£nh ho·∫∑c URL ·∫£nh.")
    
    if file and image_url:
        raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ cung c·∫•p ƒë·ªìng th·ªùi c·∫£ File ·∫£nh v√† URL ·∫£nh.")
        
    image_pil = None
    
    # Tr∆∞·ªùng h·ª£p 1: Nh·∫≠n File t·∫£i l√™n
    if file:
        # Ki·ªÉm tra lo·∫°i file
        if not file.content_type or not file.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="File t·∫£i l√™n ph·∫£i l√† ·∫£nh.")
        
        try:
            image_bytes = await file.read()
            image_pil = Image.open(io.BytesIO(image_bytes))
        except Exception:
             raise HTTPException(status_code=400, detail="File t·∫£i l√™n kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c d∆∞·ªõi d·∫°ng ·∫£nh.")

    # Tr∆∞·ªùng h·ª£p 2: Nh·∫≠n URL ·∫£nh
    elif image_url:
        try:
            # T·∫£i ·∫£nh t·ª´ URL
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(image_url)
                response.raise_for_status() 
            
            # Ki·ªÉm tra Content-Type
            content_type = response.headers.get("Content-Type", "")
            if not content_type.startswith("image/"):
                raise HTTPException(status_code=400, detail="URL kh√¥ng tr·ªè ƒë·∫øn m·ªôt file ·∫£nh h·ª£p l·ªá.")

            image_bytes = response.content
            image_pil = Image.open(io.BytesIO(image_bytes))

        except httpx.InvalidURL:
            raise HTTPException(status_code=400, detail="URL ·∫£nh kh√¥ng h·ª£p l·ªá.")
        except httpx.HTTPStatusError as e:
            raise HTTPException(status_code=400, detail=f"L·ªói khi t·∫£i ·∫£nh: {e.response.status_code} - {e.response.reason_phrase}")
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"L·ªói server khi t·∫£i ·∫£nh t·ª´ URL: {e}")
            
    # --- 2. X·ª≠ l√Ω logic nghi·ªáp v·ª• (Ph√¢n lo·∫°i v√† Sinh m√¥ t·∫£) ---
    
    try:
        # 2. Ph√¢n lo·∫°i ·∫£nh
        prediction = classify_food(image_pil)
        
        if not prediction:
            raise HTTPException(status_code=500, detail="Kh√¥ng th·ªÉ d·ª± ƒëo√°n m√≥n ƒÉn t·ª´ ·∫£nh.")
        
        # X·ª≠ l√Ω tham s·ªë ingredients
        print("Ingredients received:", ingredients)
        print("Data type of ingredients:", type(ingredients))
        # 1. Ki·ªÉm tra v√† l·∫•y ra ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
        raw_ingredients_str = ingredients[0] if ingredients and isinstance(ingredients, list) else ""
        
        # 2. T√°ch chu·ªói theo d·∫•u ph·∫©y (,) v√† l√†m s·∫°ch t·ª´ng ph·∫ßn t·ª≠
        user_extras = [
            item.strip().lower() 
            for item in raw_ingredients_str.split(',') 
            if item.strip()
        ]
        
        # 3. Sinh m√¥ t·∫£
        caption = generate_caption(
            label=prediction, 
            user_extras=user_extras
        )
        
        # 4. Tr·∫£ v·ªÅ k·∫øt qu·∫£
        return {
            "success": True, 
            "prediction": prediction,
            "caption": caption
        }
    except HTTPException as h:
        raise h 
    except Exception as e:
        # logger.error(f"L·ªói x·ª≠ l√Ω nghi·ªáp v·ª•: {e}") 
        raise HTTPException(status_code=500, detail="L·ªói server khi ph√¢n lo·∫°i v√† sinh m√¥ t·∫£.")
    